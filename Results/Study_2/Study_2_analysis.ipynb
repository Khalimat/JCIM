{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.stats.mstats import gmean\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, ttest_ind\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import friedmanchisquare\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caclculate_average_for_ds(dataset_name, path):\n",
    "    TF_AL_ds_av = []\n",
    "    TF_non_AL_ds_av = []\n",
    "    DS_ad_av = []\n",
    "    \n",
    "    for directory in Path(path).iterdir():\n",
    "        if str(directory).split('/')[-1] != 'figures':\n",
    "            if str(directory).split('/')[-1].split('_')[1] in ['SF', 'SP2']:\n",
    "                print(str(directory).split('/')[-1])\n",
    "                TF_AL = pd.read_csv(directory / 'TF_ML_AL.csv').iloc[:, 2:].mean()\n",
    "                TF_non_AL = pd.read_csv(directory / 'TF_ML_non_AL.csv').iloc[:, 2:].mean()\n",
    "                DS = pd.read_csv(directory / 'DeepSCAMs.csv').iloc[:, 2:].mean()\n",
    "                TF_AL_ds_av.append(TF_AL.tolist())\n",
    "                TF_non_AL_ds_av.append(TF_non_AL.tolist())\n",
    "                DS_ad_av.append(DS.tolist())\n",
    "    res = [np.array(it) for it in [TF_AL_ds_av, TF_non_AL_ds_av, DS_ad_av]]\n",
    "    metrics = TF_AL.index\n",
    "    return res, metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN_SF_TTS\n",
      "SMOTE_SP2_TTS\n",
      "IHT_SF_TTS\n",
      "CNN_SP2_TTS\n",
      "CNN_SF_TTS\n",
      "SMOTE_SF_TTS\n",
      "ADASYN_SP2_TTS\n",
      "IHT_SP2_TTS\n"
     ]
    }
   ],
   "source": [
    "[TF_AL_ds_av_1, TF_non_AL_ds_av_1, DS_ad_av_1], met = caclculate_average_for_ds('SF', \n",
    "                                                                         '/home/khali/scams/Results/Study_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_values_study_2 = []\n",
    "for dim, m in zip(range(TF_AL_ds_av_1.shape[1]), met):\n",
    "    _, p_al_non_al = wilcoxon(TF_AL_ds_av_1[:, dim], TF_non_AL_ds_av_1[:, dim])\n",
    "    _, p_al_DS = wilcoxon(TF_AL_ds_av_1[:, dim], DS_ad_av_1[:, dim])\n",
    "    _, p_non_al_DS = wilcoxon(TF_non_AL_ds_av_1[:, dim], DS_ad_av_1[:, dim])\n",
    "    p_values_study_2.append([p_al_non_al, p_al_DS, p_non_al_DS, m])\n",
    "p_values = pd.DataFrame(p_values_study_2, columns=['non-AL TF ML vs. AL TF ML', 'AL TF ML vs. DeepSCAMs', \n",
    "                                        'non-AL TF ML vs. DeepSCAMs', 'metric'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values.to_csv('p_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-AL TF ML vs. AL TF ML</th>\n",
       "      <th>AL TF ML vs. DeepSCAMs</th>\n",
       "      <th>non-AL TF ML vs. DeepSCAMs</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>AUC_LB_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>AUC_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>AUC_UB_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>Accuracy_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.195312</td>\n",
       "      <td>F1_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>MCC_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>AUC_LB_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>AUC_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>AUC_UB_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>Accuracy_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>F1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>MCC_validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    non-AL TF ML vs. AL TF ML  AL TF ML vs. DeepSCAMs  \\\n",
       "0                    0.007812                0.007812   \n",
       "1                    0.007812                0.007812   \n",
       "2                    0.007812                0.007812   \n",
       "3                    0.007812                0.007812   \n",
       "4                    0.007812                0.007812   \n",
       "5                    0.007812                0.007812   \n",
       "6                    0.007812                0.007812   \n",
       "7                    0.007812                0.007812   \n",
       "8                    0.007812                0.007812   \n",
       "9                    0.007812                0.007812   \n",
       "10                   0.007812                0.007812   \n",
       "11                   0.007812                0.007812   \n",
       "\n",
       "    non-AL TF ML vs. DeepSCAMs               metric  \n",
       "0                     0.945312          AUC_LB_test  \n",
       "1                     1.000000             AUC_test  \n",
       "2                     0.843750          AUC_UB_test  \n",
       "3                     0.382812        Accuracy_test  \n",
       "4                     0.195312              F1_test  \n",
       "5                     0.546875             MCC_test  \n",
       "6                     0.007812    AUC_LB_validation  \n",
       "7                     0.007812       AUC_validation  \n",
       "8                     0.007812    AUC_UB_validation  \n",
       "9                     0.007812  Accuracy_validation  \n",
       "10                    0.007812        F1_validation  \n",
       "11                    0.007812       MCC_validation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study design 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caclculate_p_each_study(path):\n",
    "    TF_AL_TF_non_AL = []\n",
    "    TF_AL_ds = []\n",
    "    study_names = []\n",
    "    TF_AL_codes = []\n",
    "    columns = []\n",
    "    for directory in Path(path).iterdir():\n",
    "        if directory.is_dir():\n",
    "            try:\n",
    "                if str(directory).split('/')[-1].split('_')[0] in ['CNN', 'IHT', 'SMOTE', 'ADASYN']:\n",
    "                    study_names.append(str(directory).split('/')[-1])\n",
    "                    TF_AL = pd.read_csv(directory / 'TF_ML_AL.csv').iloc[:, 2:]\n",
    "                    TF_non_AL = pd.read_csv(directory / 'TF_ML_non_AL.csv').iloc[:, 2:]\n",
    "                    DS = pd.read_csv(directory / 'DeepSCAMs.csv').iloc[:, 2:]\n",
    "                    run_results_1 = []\n",
    "                    run_results_2 = []\n",
    "                    code_for_TF_AL = []\n",
    "                    for col in TF_AL.columns:\n",
    "                        _, p_v_al_non_al = wilcoxon(TF_AL[col], TF_non_AL[col])\n",
    "                        run_results_1.append(p_v_al_non_al*12)\n",
    "                        _, p_v_al_ds = wilcoxon(TF_AL[col], DS[col])\n",
    "                        run_results_2.append(p_v_al_ds*12)\n",
    "                        if p_v_al_non_al*12 < 0.05 and p_v_al_ds*12 < 0.05 and TF_non_AL[col].mean() < TF_AL[col].mean() > DS[col].mean():\n",
    "                            code_for_TF_AL.append('A')\n",
    "                        elif TF_non_AL[col].mean() < TF_AL[col].mean() > DS[col].mean() and ((p_v_al_non_al*12 > 0.05 or p_v_al_ds*12 > 0.05) or (p_v_al_non_al*12 > 0.05 and p_v_al_ds*12 > 0.05)):\n",
    "                            code_for_TF_AL.append('B')\n",
    "                        else:\n",
    "                            code_for_TF_AL.append('C')\n",
    "\n",
    "                    TF_AL_TF_non_AL.append(run_results_1)\n",
    "                    TF_AL_ds.append(run_results_2)\n",
    "                    TF_AL_codes.append(code_for_TF_AL)\n",
    "            except:\n",
    "                print('not a directory')\n",
    "                \n",
    "    columns.append(TF_AL.columns.tolist())\n",
    "    return TF_AL_TF_non_AL, TF_AL_ds, TF_AL_codes, study_names, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khali/anaconda3/envs/scams_project/lib/python3.7/site-packages/scipy/stats/morestats.py:2967: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/khali/anaconda3/envs/scams_project/lib/python3.7/site-packages/scipy/stats/morestats.py:2981: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "TF_AL_TF_non_AL_2, TF_AL_ds_2, TF_AL_codes_2, directories_2, columns = caclculate_p_each_study('/home/khali/scams/Results/Study_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADASYN_SF_TTS',\n",
       " 'SMOTE_SP2_TTS',\n",
       " 'IHT_SF_TTS',\n",
       " 'CNN_SP2_TTS',\n",
       " 'CNN_SF_TTS',\n",
       " 'SMOTE_SF_TTS',\n",
       " 'ADASYN_SP2_TTS',\n",
       " 'IHT_SP2_TTS']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_codes_2 = pd.DataFrame(TF_AL_codes_2, index=[directories_2], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_codes_2.to_csv('TF_AL_codes_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_AL_codes_2.isin(['C']).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_AL_codes_2.isin(['B']).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_AL_codes_2.isin(['A']).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12/(12+84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "84/(12+84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_TF_non_AL_2 = pd.DataFrame(TF_AL_TF_non_AL_2, index=[directories_2], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_TF_non_AL_2.to_csv('TF_AL_TF_non_AL_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_ds_2 = pd.DataFrame(TF_AL_ds_2, index=[directories_2], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_AL_ds_2.to_csv('TF_AL_ds_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scams_project",
   "language": "python",
   "name": "scams_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
